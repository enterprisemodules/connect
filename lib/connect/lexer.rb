#--
# DO NOT MODIFY!!!!
# This file is automatically generated by rex 1.0.5
# from lexical definition file "lib/connect/dsl.rex".
#++

require 'racc/parser'
module Connect
  class Dsl < Racc::Parser
    require 'strscan'

    class ScanError < StandardError; end

    attr_reader   :lineno
    attr_reader   :filename
    attr_accessor :state

    def scan_setup(str)
      @ss = StringScanner.new(str)
      @lineno = 1
      @state  = nil
    end

    def action
      yield
    end

    def scan_str(str)
      scan_setup(str)
      do_parse
    end
    alias scan scan_str

    def load_file(filename)
      @filename = filename
      open(filename, 'r') do |f|
        scan_setup(f.read)
      end
    end

    def scan_file(filename)
      load_file(filename)
      do_parse
    end

    def next_token
      return if @ss.eos?

      # skips empty actions
      until (token = _next_token) || @ss.eos?; end
      token
    end

    def _next_token
      text = @ss.peek(1)
      @lineno += 1 if text == "\n"
      token = case @state
              when nil
                if (text = @ss.scan(/\n/))

                elsif (text = @ss.scan(/\#.*\n/))
                  action { @lineno += 1; nil }

                elsif (text = @ss.scan(/\#.*$/))

                elsif (text = @ss.scan(/iterate\s/))
                  action { [:ITERATE, text] }

                elsif (text = @ss.scan(/step\s/))
                  action { [:STEP, text] }

                elsif (text = @ss.scan(/or\s|(\|\|)/))
                  action { [:OR, text] }

                elsif (text = @ss.scan(/and\s|\&\&/))
                  action { [:AND, text] }

                elsif (text = @ss.scan(/do\s/))
                  action { [:DO, text] }

                elsif (text = @ss.scan(/end\s/))
                  action { [:END, text] }

                elsif (text = @ss.scan(/from\s/))
                  action { [:FROM, text] }

                elsif (text = @ss.scan(/to\s/))
                  action { [:TO, text] }

                elsif (text = @ss.scan(/import\s/))
                  action { [:IMPORT, text] }

                elsif (text = @ss.scan(/into\s/))
                  action { [:INTO, text] }

                elsif (text = @ss.scan(/with\s/))
                  action { [:WITH, text] }

                elsif (text = @ss.scan(/include\s/))
                  action { [:INCLUDE, text] }

                elsif (text = @ss.scan(/TRUE|true/))
                  action { [:BOOLEAN, true] }

                elsif (text = @ss.scan(/FALSE|false/))
                  action { [:BOOLEAN, false] }

                elsif (text = @ss.scan(/undefined|undef|nil/))
                  action { [:UNDEF, nil] }

                elsif (text = @ss.scan(/(?:(?:[a-zA-Z][a-zA-Z0-9_]*)?::)+/))
                  action { [:SCOPE, text] }

                elsif (text = @ss.scan(/[a-zA-Z][a-zA-Z0-9_]*/))
                  action { [:IDENTIFIER, text] }

                elsif (text = @ss.scan(/\=\>/))
                  action { [:HASH_ROCKET, text] }

                elsif (text = @ss.scan(/[0-9]+\.[0-9]+/))
                  action { [:FLOAT, text.to_f] }

                elsif (text = @ss.scan(/[0-9]+/))
                  action { [:INTEGER, text.to_i] }

                elsif (text = @ss.scan(/\"(\\.|[^\\"])*\"/))
                  action { [:DOUBLE_QUOTED, dequote(text)] }

                elsif (text = @ss.scan(/\'(\\.|[^\\'])*\'/))
                  action { [:SINGLE_QUOTED, dequote(text)] }

                elsif (text = @ss.scan(/\/.*\//))
                  action { [:REGEXP, dequote(text)] }

                elsif (text = @ss.scan(/\.\./))
                  action { [:DOUBLE_DOTS, text] }

                elsif (text = @ss.scan(/[\s|\t]+/))

                elsif (text = @ss.scan(/./))
                  action { [text, text] }

                else
                  text = @ss.string[@ss.pos..-1]
                  raise  ScanError, "can not match: '" + text + "'"
                end # if

              else
                raise ScanError, "undefined state: '" + state.to_s + "'"
      end # case state
      token
    end # def _next_token

    def dequote(line)
      line.chop![0] = ''
      line
    end

    def tokenize(code)
      scan_setup(code)
      tokens = []
      while token = next_token
        tokens << token
      end
      tokens
    end
    end
end # class
